"""
ë°ì´í„° ì €ì¥ ë° ê´€ë¦¬ ëª¨ë“ˆ
í¬ë¡¤ë§ëœ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ê³  ê´€ë¦¬
"""

import os
import json
import gzip
import shutil
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Union

from config import DATA_DIR, BANK_LIST_FILE
from parser import parse_summary_data

logger = logging.getLogger(__name__)


class StorageManager:
    """ë°ì´í„° ì €ì¥ì†Œ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir: str = DATA_DIR):
        """ì €ì¥ì†Œ ì´ˆê¸°í™”"""
        self.data_dir = Path(data_dir)
        self.rates_dir = self.data_dir / 'rates'
        self.backup_dir = self.data_dir / 'backups'
        self.bank_list_file = Path(BANK_LIST_FILE)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self._ensure_directories()
    
    def _ensure_directories(self) -> None:
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        for directory in [self.data_dir, self.rates_dir, self.backup_dir]:
            directory.mkdir(parents=True, exist_ok=True)
    
    def save_json(self, data: Any, filepath: Union[str, Path], 
                  compress: bool = False, pretty: bool = True) -> bool:
        """
        ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            data: ì €ì¥í•  ë°ì´í„°
            filepath: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            compress: gzip ì••ì¶• ì—¬ë¶€
            pretty: ì˜ˆì˜ê²Œ í¬ë§·íŒ…í• ì§€ ì—¬ë¶€
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        filepath = Path(filepath)
        
        try:
            # ë””ë ‰í† ë¦¬ í™•ì¸
            filepath.parent.mkdir(parents=True, exist_ok=True)
            
            # JSON ì§ë ¬í™” ì˜µì…˜
            json_kwargs = {
                'ensure_ascii': False,
                'separators': (',', ': ') if pretty else (',', ':')
            }
            if pretty:
                json_kwargs['indent'] = 2
            
            if compress:
                # gzip ì••ì¶• ì €ì¥
                filepath = filepath.with_suffix('.json.gz')
                with gzip.open(filepath, 'wt', encoding='utf-8') as f:
                    json.dump(data, f, **json_kwargs)
            else:
                # ì¼ë°˜ ì €ì¥
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(data, f, **json_kwargs)
            
            logger.info(f"âœ“ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"âœ— íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ ({filepath}): {e}")
            return False
    
    def load_json(self, filepath: Union[str, Path]) -> Optional[Any]:
        """
        JSON íŒŒì¼ ë¡œë“œ
        
        Args:
            filepath: ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë¡œë“œëœ ë°ì´í„° ë˜ëŠ” None
        """
        filepath = Path(filepath)
        
        # gzip íŒŒì¼ í™•ì¸
        if not filepath.exists() and filepath.with_suffix('.json.gz').exists():
            filepath = filepath.with_suffix('.json.gz')
        
        if not filepath.exists():
            logger.debug(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {filepath}")
            return None
        
        try:
            if filepath.suffix == '.gz':
                with gzip.open(filepath, 'rt', encoding='utf-8') as f:
                    return json.load(f)
            else:
                with open(filepath, 'r', encoding='utf-8') as f:
                    return json.load(f)
                    
        except Exception as e:
            logger.error(f"âœ— íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({filepath}): {e}")
            return None
    
    def save_bank_list(self, banks: List[Dict[str, Any]]) -> bool:
        """ì€í–‰ ëª©ë¡ ì €ì¥"""
        if not banks:
            logger.warning("ì €ì¥í•  ì€í–‰ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # ë°±ì—… ìƒì„±
        self._create_backup(self.bank_list_file)
        
        # ì¤‘ë³µ ì œê±°
        unique_banks = self._remove_duplicate_banks(banks)
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        bank_data = {
            'metadata': {
                'total_count': len(unique_banks),
                'unique_count': len(set(b['gmgoCd'] for b in unique_banks)),
                'crawled_at': datetime.now().isoformat(),
                'version': '1.1'
            },
            'banks': unique_banks
        }
        
        success = self.save_json(bank_data, self.bank_list_file)
        if success:
            logger.info(f"ğŸ¦ ì€í–‰ ëª©ë¡ ì €ì¥ ì™„ë£Œ: {len(unique_banks)}ê°œ")
        
        return success
    
    def load_banks(self) -> Optional[Dict[str, Any]]:
        """ì€í–‰ ëª©ë¡ ë¡œë“œ"""
        try:
            if not self.bank_list_file.exists():
                return None
            
            with open(self.bank_list_file, 'r', encoding='utf-8') as f:
                return json.load(f)
                
        except Exception as e:
            logger.error(f"ì€í–‰ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def save_daily_rates(self, rates: List[Dict[str, Any]], 
                        date_str: Optional[str] = None) -> bool:
        """ì¼ë³„ ê¸ˆë¦¬ ë°ì´í„° ì €ì¥"""
        if not rates:
            logger.warning("ì €ì¥í•  ê¸ˆë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        if date_str is None:
            date_str = datetime.now().strftime('%Y-%m-%d')
        
        filepath = self.rates_dir / f"{date_str}.json"
        
        # ë°±ì—… ìƒì„±
        self._create_backup(filepath)
        
        # ìš”ì•½ í†µê³„ ìƒì„±
        summary = parse_summary_data(rates)
        
        # ë°ì´í„° êµ¬ì„±
        rates_data = {
            'metadata': {
                'date': date_str,
                'total_banks': len(rates),
                'successful_banks': len([r for r in rates if r.get('total_products', 0) > 0]),
                'crawled_at': datetime.now().isoformat(),
                'version': '1.1'
            },
            'summary': summary,
            'rates': rates
        }
        
        # ì••ì¶• ì˜µì…˜ (í° íŒŒì¼ì˜ ê²½ìš°)
        compress = len(rates) > 100
        
        success = self.save_json(rates_data, filepath, compress=compress)
        if success:
            logger.info(f"ğŸ’° ê¸ˆë¦¬ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {date_str} ({len(rates)}ê°œ ê¸ˆê³ )")
        
        return success
    
    def save_summary(self, summary_data: Dict[str, Any], 
                    date_str: Optional[str] = None) -> bool:
        """ìš”ì•½ ì •ë³´ ì €ì¥"""
        if date_str is None:
            date_str = datetime.now().strftime('%Y-%m-%d')
        
        summary_file = self.data_dir / 'summary.json'
        
        # ê¸°ì¡´ ìš”ì•½ ë°ì´í„° ë¡œë“œ
        existing_summary = self.load_json(summary_file) or {}
        
        # ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€
        existing_summary[date_str] = summary_data
        
        # ìµœê·¼ 90ì¼ì¹˜ë§Œ ìœ ì§€
        cutoff_date = datetime.now() - timedelta(days=90)
        existing_summary = {
            date: data for date, data in existing_summary.items()
            if datetime.strptime(date, '%Y-%m-%d') >= cutoff_date
        }
        
        success = self.save_json(existing_summary, summary_file)
        if success:
            logger.info(f"ğŸ“Š ìš”ì•½ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {date_str}")
        
        return success
    
    def _remove_duplicate_banks(self, banks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì€í–‰ ì œê±°"""
        seen = set()
        unique = []
        
        for bank in banks:
            key = bank.get('gmgoCd')
            if key and key not in seen:
                seen.add(key)
                unique.append(bank)
        
        if len(banks) != len(unique):
            logger.info(f"ì¤‘ë³µ ì œê±°: {len(banks)} â†’ {len(unique)}ê°œ")
        
        return unique
    
    def _create_backup(self, filepath: Union[str, Path]) -> bool:
        """íŒŒì¼ ë°±ì—… ìƒì„±"""
        filepath = Path(filepath)
        
        if not filepath.exists():
            return False
        
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_name = f"{filepath.stem}_{timestamp}{filepath.suffix}"
            backup_path = self.backup_dir / backup_name
            
            shutil.copy2(filepath, backup_path)
            logger.debug(f"ë°±ì—… ìƒì„±: {backup_path}")
            
            # ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ (7ì¼ ì´ìƒ)
            self._cleanup_old_backups()
            
            return True
            
        except Exception as e:
            logger.warning(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _cleanup_old_backups(self, days_to_keep: int = 7) -> None:
        """ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬"""
        if not self.backup_dir.exists():
            return
        
        cutoff_time = datetime.now() - timedelta(days=days_to_keep)
        
        for backup_file in self.backup_dir.glob('*'):
            if backup_file.stat().st_mtime < cutoff_time.timestamp():
                backup_file.unlink()
                logger.debug(f"ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ: {backup_file}")
    
    def get_latest_rates(self) -> Optional[Dict[str, Any]]:
        """ìµœì‹  ê¸ˆë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        if not self.rates_dir.exists():
            return None
        
        # JSON ë° ì••ì¶• íŒŒì¼ ëª¨ë‘ ê²€ìƒ‰
        rate_files = list(self.rates_dir.glob('*.json')) + \
                    list(self.rates_dir.glob('*.json.gz'))
        
        if not rate_files:
            return None
        
        # ìµœì‹  íŒŒì¼ ì„ íƒ
        latest_file = max(rate_files, key=lambda f: f.stem.replace('.json', ''))
        
        return self.load_json(latest_file)
    
    def get_rates_by_date(self, date_str: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ë‚ ì§œì˜ ê¸ˆë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        filepath = self.rates_dir / f"{date_str}.json"
        return self.load_json(filepath)
    
    def list_available_dates(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ëª©ë¡ ë°˜í™˜"""
        if not self.rates_dir.exists():
            return []
        
        # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
        dates = []
        for file in self.rates_dir.glob('*.json*'):
            date_str = file.stem.replace('.json', '')
            try:
                # ë‚ ì§œ í˜•ì‹ ê²€ì¦
                datetime.strptime(date_str, '%Y-%m-%d')
                dates.append(date_str)
            except ValueError:
                continue
        
        return sorted(dates, reverse=True)
    
    def save_grades(self, grades_data: List[Dict[str, Any]]) -> bool:
        """ê²½ì˜ì‹¤íƒœí‰ê°€ ë°ì´í„° ì €ì¥"""
        try:
            # grades ë””ë ‰í† ë¦¬ ìƒì„±
            grades_dir = self.data_dir / "grades"
            grades_dir.mkdir(exist_ok=True)
            
            # íŒŒì¼ëª…: grades_YYYY_MM.json (ì›” ì •ë³´ í¬í•¨)
            if grades_data:
                evaluation_year = grades_data[0]['evaluation_year']
                evaluation_month = grades_data[0]['evaluation_month']
                filename = f"grades_{evaluation_year}_{evaluation_month:02d}.json"
            else:
                current_year = datetime.now().year
                current_month = datetime.now().month
                filename = f"grades_{current_year}_{current_month:02d}.json"
            filepath = grades_dir / filename
            
            # ë°ì´í„° êµ¬ì„±
            data = {
                "collection_info": {
                    "collected_at": datetime.now().isoformat(),
                    "total_banks": len(grades_data),
                    "evaluation_year": grades_data[0]['evaluation_year'] if grades_data else None,
                    "evaluation_month": grades_data[0]['evaluation_month'] if grades_data else None
                },
                "grades": grades_data
            }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ“ ê²½ì˜ì‹¤íƒœí‰ê°€ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
            return True
            
        except Exception as e:
            print(f"âŒ ê²½ì˜ì‹¤íƒœí‰ê°€ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def load_grades(self, year: int = None, month: int = None) -> Optional[Dict[str, Any]]:
        """ê²½ì˜ì‹¤íƒœí‰ê°€ ë°ì´í„° ë¡œë“œ"""
        try:
            if year is None:
                year = datetime.now().year
            if month is None:
                month = datetime.now().month
            
            grades_dir = self.data_dir / "grades"
            filepath = grades_dir / f"grades_{year}_{month:02d}.json"
            
            if not filepath.exists():
                return None
            
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
                
        except Exception as e:
            print(f"âŒ ê²½ì˜ì‹¤íƒœí‰ê°€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_grade_by_gmgo_cd(self, gmgo_cd: str, year: int = None, month: int = None) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ê¸ˆê³  ì½”ë“œì˜ ê²½ì˜ì‹¤íƒœí‰ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        grades_data = self.load_grades(year, month)
        if not grades_data:
            return None
        
        for grade in grades_data.get('grades', []):
            if grade.get('gmgo_cd') == gmgo_cd:
                return grade
        
        return None
    
    def cleanup_old_data(self, days_to_keep: int = 30) -> int:
        """
        ì˜¤ë˜ëœ ë°ì´í„° íŒŒì¼ ì •ë¦¬
        
        Args:
            days_to_keep: ë³´ê´€í•  ì¼ìˆ˜
            
        Returns:
            ì‚­ì œëœ íŒŒì¼ ìˆ˜
        """
        if not self.rates_dir.exists():
            return 0
        
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        removed_count = 0
        
        for file in self.rates_dir.glob('*.json*'):
            try:
                date_str = file.stem.replace('.json', '')
                file_date = datetime.strptime(date_str, '%Y-%m-%d')
                
                if file_date < cutoff_date:
                    file.unlink()
                    removed_count += 1
                    logger.info(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ: {file.name}")
                    
            except (ValueError, OSError) as e:
                logger.warning(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {file.name} - {e}")
        
        if removed_count > 0:
            logger.info(f"ğŸ§¹ ì •ë¦¬ ì™„ë£Œ: {removed_count}ê°œ íŒŒì¼ ì‚­ì œ")
        
        return removed_count
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """ì €ì¥ì†Œ í†µê³„ ì •ë³´ ë°˜í™˜"""
        stats = {
            'data_directory': str(self.data_dir),
            'bank_list_exists': self.bank_list_file.exists(),
            'rates_directory_exists': self.rates_dir.exists(),
            'backup_directory_exists': self.backup_dir.exists(),
            'available_dates': self.list_available_dates(),
            'total_rate_files': 0,
            'total_backup_files': 0,
            'latest_date': None,
            'storage_size_mb': 0
        }
        
        # íŒŒì¼ ìˆ˜ ê³„ì‚°
        if self.rates_dir.exists():
            rate_files = list(self.rates_dir.glob('*.json*'))
            stats['total_rate_files'] = len(rate_files)
            if rate_files:
                stats['latest_date'] = max(
                    f.stem.replace('.json', '') for f in rate_files
                )
        
        if self.backup_dir.exists():
            stats['total_backup_files'] = len(list(self.backup_dir.glob('*')))
        
        # ì „ì²´ ì €ì¥ì†Œ í¬ê¸° ê³„ì‚°
        total_size = 0
        for file in self.data_dir.rglob('*'):
            if file.is_file():
                total_size += file.stat().st_size
        
        stats['storage_size_mb'] = round(total_size / (1024 * 1024), 2)
        
        return stats


# ëª¨ë“ˆ ë ˆë²¨ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€)
_storage_manager = StorageManager()

def save_all(banks: List[Dict[str, Any]], rates: List[Dict[str, Any]], 
            date_str: Optional[str] = None) -> bool:
    """ëª¨ë“  ë°ì´í„°ë¥¼ ì €ì¥"""
    if date_str is None:
        date_str = datetime.now().strftime('%Y-%m-%d')
    
    logger.info("ğŸ’¾ ë°ì´í„° ì €ì¥ ì‹œì‘...")
    
    try:
        success = True
        
        # 1. ì€í–‰ ëª©ë¡ ì €ì¥
        if banks:
            success &= _storage_manager.save_bank_list(banks)
        
        # 2. ê¸ˆë¦¬ ë°ì´í„° ì €ì¥
        if rates:
            success &= _storage_manager.save_daily_rates(rates, date_str)
            
            # 3. ìš”ì•½ ë°ì´í„° ì €ì¥
            summary = parse_summary_data(rates)
            success &= _storage_manager.save_summary(summary, date_str)
        
        if success:
            logger.info("âœ… ëª¨ë“  ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ ì¼ë¶€ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def get_latest_rates() -> Optional[Dict[str, Any]]:
    """ìµœì‹  ê¸ˆë¦¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´"""
    return _storage_manager.get_latest_rates()

def get_rates_by_date(date_str: str) -> Optional[Dict[str, Any]]:
    """íŠ¹ì • ë‚ ì§œì˜ ê¸ˆë¦¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´"""
    return _storage_manager.get_rates_by_date(date_str)

def list_available_dates() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ëª©ë¡ì„ ë°˜í™˜"""
    return _storage_manager.list_available_dates()

def cleanup_old_data(days_to_keep: int = 30) -> int:
    """ì˜¤ë˜ëœ ë°ì´í„° íŒŒì¼ ì •ë¦¬"""
    return _storage_manager.cleanup_old_data(days_to_keep)

def get_storage_stats() -> Dict[str, Any]:
    """ì €ì¥ì†Œ í†µê³„ ì •ë³´ ë°˜í™˜"""
    return _storage_manager.get_storage_stats()