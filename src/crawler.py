import requests
import time
import logging
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass
from urllib.parse import urlencode

from config import REGIONS, CRAWLER_CONFIG, API_ENDPOINTS
from parser import parse_bank_list, parse_interest_rates

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class Bank:
    """ì€í–‰ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    gmgoCd: str
    name: str
    city: str
    district: str
    address: str = ""
    phone: str = ""
    type: str = ""
    crawled_at: str = ""


@dataclass
class InterestRate:
    """ê¸ˆë¦¬ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    bank: Dict[str, Any]
    base_date: str
    products: List[Dict[str, Any]]
    crawled_at: str
    total_products: int


class KFCCCrawler:
    """ìƒˆë§ˆì„ê¸ˆê³  ê¸ˆë¦¬ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
        self.session = self._create_session()
        self.stats = {
            'banks_fetched': 0,
            'rates_fetched': 0,
            'errors': []
        }
    
    def _create_session(self) -> requests.Session:
        """ì„¸ì…˜ ìƒì„± ë° í—¤ë” ì„¤ì •"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        return session
    
    def _make_request(self, url: str, params: Dict[str, Any], 
                     max_retries: int = 3) -> Optional[requests.Response]:
        """HTTP ìš”ì²­ ì²˜ë¦¬ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        for attempt in range(max_retries):
            try:
                response = self.session.get(
                    url, 
                    params=params, 
                    timeout=CRAWLER_CONFIG['timeout']
                )
                response.raise_for_status()
                return response
                
            except requests.exceptions.RequestException as e:
                logger.warning(f"ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(CRAWLER_CONFIG['retry_delay'] * (attempt + 1))
                else:
                    logger.error(f"ìµœì¢… ìš”ì²­ ì‹¤íŒ¨: {url} with params {params}")
                    return None
        return None
    
    def fetch_bank_list(self, city: str, district: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì§€ì—­ì˜ ìƒˆë§ˆì„ê¸ˆê³  ëª©ë¡ì„ ê°€ì ¸ì˜´"""
        # í•˜ìœ„ ë©”ë‰´ê°€ 1ê°œì´ê³  cityì™€ ê°™ì€ ê²½ìš° ì²˜ë¦¬
        if city in REGIONS and len(REGIONS[city]) == 1 and REGIONS[city][0] == city:
            params = {'r1': city, 'r2': ''}
        else:
            params = {'r1': city, 'r2': district}
        
        response = self._make_request(
            API_ENDPOINTS['bank_list'], 
            params, 
            CRAWLER_CONFIG['retry_count']
        )
        
        if not response:
            logger.error(f"ì€í–‰ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {city} {district}")
            return []
        
        try:
            banks = parse_bank_list(response.text, city, district)
            logger.info(f"âœ“ {city} {district}: {len(banks)}ê°œ ê¸ˆê³  ìˆ˜ì§‘ ì™„ë£Œ")
            self.stats['banks_fetched'] += len(banks)
            return banks
        except Exception as e:
            logger.error(f"íŒŒì‹± ì˜¤ë¥˜: {city} {district} - {e}")
            self.stats['errors'].append(f"{city} {district}: {str(e)}")
            return []
    
    def fetch_interest_rates(self, bank: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ê¸ˆê³ ì˜ ê¸ˆë¦¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜´"""
        if 'gmgoCd' not in bank:
            logger.warning(f"{bank.get('name', 'Unknown')}: ê¸ˆê³  ì½”ë“œ ì—†ìŒ")
            return None
        
        all_products = []
        product_types = [
            {'code': '12', 'name': 'ìš”êµ¬ë¶ˆì˜ˆíƒê¸ˆ'},
            {'code': '13', 'name': 'ê±°ì¹˜ì‹ì˜ˆíƒê¸ˆ'},
            {'code': '14', 'name': 'ì ë¦½ì‹ì˜ˆíƒê¸ˆ'}
        ]
        
        for product_type in product_types:
            params = {
                'OPEN_TRMID': bank['gmgoCd'],
                'gubuncode': product_type['code']
            }
            
            response = self._make_request(
                API_ENDPOINTS['interest_rates'],
                params,
                CRAWLER_CONFIG['retry_count']
            )
            
            if response:
                try:
                    products = parse_interest_rates(
                        response.text, 
                        bank, 
                        product_type['name']
                    )
                    if products:
                        all_products.extend(products)
                except Exception as e:
                    logger.warning(f"íŒŒì‹± ì˜¤ë¥˜: {bank['name']} - {product_type['name']}: {e}")
        
        # ì¤‘ë³µ ì œê±°
        unique_products = self._remove_duplicate_products(all_products)
        
        if unique_products:
            result = InterestRate(
                bank=bank,
                base_date='',
                products=unique_products,
                crawled_at=datetime.now().isoformat(),
                total_products=len(unique_products)
            ).__dict__
            
            logger.info(f"âœ“ {bank['name']}: {len(unique_products)}ê°œ ìƒí’ˆ ê¸ˆë¦¬ ìˆ˜ì§‘ ì™„ë£Œ")
            self.stats['rates_fetched'] += 1
            return result
        else:
            logger.warning(f"{bank['name']}: ê¸ˆë¦¬ ì •ë³´ ì—†ìŒ")
            return None
    
    def _remove_duplicate_products(self, products: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ìƒí’ˆ ì œê±°"""
        seen = set()
        unique = []
        
        for product in products:
            key = (
                product['product_name'], 
                product['duration_months'], 
                product['interest_rate'], 
                product['product_type']
            )
            if key not in seen:
                seen.add(key)
                unique.append(product)
        
        return unique
    
    def collect_bank_lists_parallel(self) -> List[Dict[str, Any]]:
        """ëª¨ë“  ì§€ì—­ì˜ ê¸ˆê³  ëª©ë¡ì„ ë³‘ë ¬ë¡œ ìˆ˜ì§‘"""
        logger.info("ğŸ¦ ì€í–‰ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘...")
        all_banks = []
        
        # ëª¨ë“  ì§€ì—­ ì •ë³´ë¥¼ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ì¤€ë¹„
        regions_to_fetch = [
            (city, district) 
            for city, districts in REGIONS.items() 
            for district in districts
        ]
        
        with ThreadPoolExecutor(max_workers=CRAWLER_CONFIG['max_workers_list']) as executor:
            # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ ì¹´ìš´í„°
            completed = 0
            total = len(regions_to_fetch)
            
            future_to_region = {
                executor.submit(self.fetch_bank_list, city, district): (city, district)
                for city, district in regions_to_fetch
            }
            
            for future in as_completed(future_to_region):
                city, district = future_to_region[future]
                try:
                    banks = future.result()
                    if banks:
                        all_banks.extend(banks)
                    
                    completed += 1
                    if completed % 10 == 0:
                        logger.info(f"ì§„í–‰ë¥ : {completed}/{total} ({completed/total*100:.1f}%)")
                        
                except Exception as e:
                    logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {city} {district} - {e}")
                    self.stats['errors'].append(f"{city} {district}: {str(e)}")
        
        logger.info(f"ğŸ¦ ì´ {len(all_banks)}ê°œ ê¸ˆê³  ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_banks
    
    def collect_interest_rates_parallel(self, banks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ëª¨ë“  ê¸ˆê³ ì˜ ê¸ˆë¦¬ ì •ë³´ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜ì§‘"""
        logger.info("ğŸ’° ê¸ˆë¦¬ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
        all_rates = []
        
        with ThreadPoolExecutor(max_workers=CRAWLER_CONFIG['max_workers_rate']) as executor:
            completed = 0
            total = len(banks)
            
            future_to_bank = {
                executor.submit(self.fetch_interest_rates, bank): bank
                for bank in banks
            }
            
            for future in as_completed(future_to_bank):
                bank = future_to_bank[future]
                try:
                    rates = future.result()
                    if rates:
                        all_rates.append(rates)
                    
                    completed += 1
                    if completed % 20 == 0:
                        logger.info(f"ì§„í–‰ë¥ : {completed}/{total} ({completed/total*100:.1f}%)")
                        
                except Exception as e:
                    logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {bank.get('name', 'Unknown')} - {e}")
                    self.stats['errors'].append(f"{bank.get('name', 'Unknown')}: {str(e)}")
        
        logger.info(f"ğŸ’° ì´ {len(all_rates)}ê°œ ê¸ˆê³ ì˜ ê¸ˆë¦¬ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_rates
    
    def run(self) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """ì „ì²´ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        logger.info("ğŸš€ ìƒˆë§ˆì„ê¸ˆê³  ê¸ˆë¦¬ í¬ë¡¤ë§ ì‹œì‘")
        start_time = time.time()
        
        try:
            # 1ë‹¨ê³„: ì€í–‰ ëª©ë¡ ìˆ˜ì§‘
            banks = self.collect_bank_lists_parallel()
            if not banks:
                logger.error("âŒ ì€í–‰ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨")
                return [], []
            
            # 2ë‹¨ê³„: ê¸ˆë¦¬ ì •ë³´ ìˆ˜ì§‘
            rates = self.collect_interest_rates_parallel(banks)
            
            # ê²°ê³¼ ìš”ì•½
            elapsed_time = time.time() - start_time
            logger.info(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(banks)}ê°œ ê¸ˆê³ , {len(rates)}ê°œ ê¸ˆë¦¬ ì •ë³´")
            logger.info(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            
            # í†µê³„ ì¶œë ¥
            self._print_statistics()
            
            return banks, rates
            
        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return [], []
        finally:
            self.session.close()
    
    def _print_statistics(self) -> None:
        """ìˆ˜ì§‘ í†µê³„ ì¶œë ¥"""
        logger.info("=" * 50)
        logger.info("ğŸ“Š ìˆ˜ì§‘ í†µê³„")
        logger.info(f"  - ìˆ˜ì§‘ëœ ì€í–‰ ìˆ˜: {self.stats['banks_fetched']}")
        logger.info(f"  - ìˆ˜ì§‘ëœ ê¸ˆë¦¬ ì •ë³´: {self.stats['rates_fetched']}")
        logger.info(f"  - ì˜¤ë¥˜ ë°œìƒ ìˆ˜: {len(self.stats['errors'])}")
        
        if self.stats['errors']:
            logger.warning("âš ï¸ ì˜¤ë¥˜ ë°œìƒ ëª©ë¡:")
            for error in self.stats['errors'][:10]:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
                logger.warning(f"  - {error}")
            if len(self.stats['errors']) > 10:
                logger.warning(f"  ... ì™¸ {len(self.stats['errors']) - 10}ê°œ")
    
    def get_region_stats(self, banks: List[Dict[str, Any]]) -> Dict[str, Dict[str, int]]:
        """ì§€ì—­ë³„ í†µê³„ ì •ë³´ ìƒì„±"""
        stats = {}
        for bank in banks:
            city = bank.get('city', 'Unknown')
            district = bank.get('district', 'Unknown')
            
            if city not in stats:
                stats[city] = {}
            if district not in stats[city]:
                stats[city][district] = 0
            stats[city][district] += 1
        
        return stats